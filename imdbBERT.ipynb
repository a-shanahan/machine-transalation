{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNoPnkC4cJqejXu8MBgIGbh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB BERT\n",
        "\n",
        "A simple BERT model trained from scratch using the IMDB dataset"
      ],
      "metadata": {
        "id": "RUpVXX18ZkyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment prep and data download"
      ],
      "metadata": {
        "id": "s-Dhi28lZw--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q -U tensorflow-text tensorflow"
      ],
      "metadata": {
        "id": "ADCadizHRx4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcZHpgIcehFB",
        "outputId": "75f55aad-d040-48f8-8a1d-53668ce6b55f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  5703k      0  0:00:14  0:00:14 --:--:-- 12.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data processing\n",
        "\n",
        "Import all the libraries needed"
      ],
      "metadata": {
        "id": "XmUAg-1AZ7Gk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uilFdLnoPBoM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "from typing import Tuple\n",
        "import re\n",
        "import glob\n",
        "import functools\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_list_from_files(files: list) -> list:\n",
        "    \"\"\"\n",
        "    Read in data from files\n",
        "    :param files: File list\n",
        "    :return: Text list\n",
        "    \"\"\"\n",
        "    text_list = []\n",
        "    for name in files:\n",
        "        with open(name) as f:\n",
        "            for line in f:\n",
        "                text_list.append(line)\n",
        "    return text_list\n",
        "\n",
        "\n",
        "def get_data_from_text_files(folder_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extract data from downloaded files\n",
        "    :param folder_name: Directory name\n",
        "    :return: Dataframe containing text\n",
        "    \"\"\"\n",
        "    pos_files = glob.glob(\"aclImdb/\" + folder_name + \"/pos/*.txt\")\n",
        "    pos_texts = get_text_list_from_files(pos_files)\n",
        "    neg_files = glob.glob(\"aclImdb/\" + folder_name + \"/neg/*.txt\")\n",
        "    neg_texts = get_text_list_from_files(neg_files)\n",
        "    df = pd.DataFrame(\n",
        "        {\n",
        "            \"review\": pos_texts + neg_texts,\n",
        "            \"sentiment\": [0] * len(pos_texts) + [1] * len(neg_texts),\n",
        "        }\n",
        "    )\n",
        "    df = df.sample(len(df)).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "train_df = get_data_from_text_files(\"train\")\n",
        "test_df = get_data_from_text_files(\"test\")\n",
        "\n",
        "all_data = train_df.append(test_df)\n",
        "all_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "21oIXkZIerUE",
        "outputId": "d1e36f88-123c-49f9-89ab-4ca80f49e83d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  Hoo boy, this was a real trial to get through....          1\n",
              "1  I've noticed that a lot of people who post on ...          0\n",
              "2  I know John Singleton's a smart guy 'coz he ma...          1\n",
              "3  This was a less than exciting short film I saw...          1\n",
              "4  I would not like to comment on how good the mo...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21ea9580-985b-4a6d-8a16-b33141294ff0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hoo boy, this was a real trial to get through....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I've noticed that a lot of people who post on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I know John Singleton's a smart guy 'coz he ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This was a less than exciting short film I saw...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I would not like to comment on how good the mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21ea9580-985b-4a6d-8a16-b33141294ff0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21ea9580-985b-4a6d-8a16-b33141294ff0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21ea9580-985b-4a6d-8a16-b33141294ff0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cln_text(text: str) -> bytes:\n",
        "    \"\"\"\n",
        "    Remove ALL punctuation and html tags from text\n",
        "    :param text: Text to clean\n",
        "    :return: Cleansed text\n",
        "    \"\"\"\n",
        "    lowercase = tf.strings.lower(text)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "            stripped_html, \"[%s]\" % re.escape(\"!#$%&'()*+-/:;<=>?@\\^_`{|}~.,\"), \"\").numpy()\n",
        "\n",
        "all_data['review_cln'] = all_data['review'].map(cln_text)\n",
        "all_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-OW_hz9PLKu2",
        "outputId": "c3fda8fe-67f6-4b8e-fae2-a37e80e864e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment  \\\n",
              "0  Hoo boy, this was a real trial to get through....          1   \n",
              "1  I've noticed that a lot of people who post on ...          0   \n",
              "2  I know John Singleton's a smart guy 'coz he ma...          1   \n",
              "3  This was a less than exciting short film I saw...          1   \n",
              "4  I would not like to comment on how good the mo...          0   \n",
              "\n",
              "                                          review_cln  \n",
              "0  b'hoo boy this was a real trial to get through...  \n",
              "1  b'ive noticed that a lot of people who post on...  \n",
              "2  b'i know john singletons a smart guy coz he ma...  \n",
              "3  b'this was a less than exciting short film i s...  \n",
              "4  b'i would not like to comment on how good the ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ecb25f9-9004-4c1a-9121-ff2e611966f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_cln</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hoo boy, this was a real trial to get through....</td>\n",
              "      <td>1</td>\n",
              "      <td>b'hoo boy this was a real trial to get through...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I've noticed that a lot of people who post on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>b'ive noticed that a lot of people who post on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I know John Singleton's a smart guy 'coz he ma...</td>\n",
              "      <td>1</td>\n",
              "      <td>b'i know john singletons a smart guy coz he ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This was a less than exciting short film I saw...</td>\n",
              "      <td>1</td>\n",
              "      <td>b'this was a less than exciting short film i s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I would not like to comment on how good the mo...</td>\n",
              "      <td>0</td>\n",
              "      <td>b'i would not like to comment on how good the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ecb25f9-9004-4c1a-9121-ff2e611966f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ecb25f9-9004-4c1a-9121-ff2e611966f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ecb25f9-9004-4c1a-9121-ff2e611966f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate TensorFlow Datasets\n",
        "\n",
        "Save data as TensorFlow datasets for use with the model later"
      ],
      "metadata": {
        "id": "nZEs7AAkaJqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(all_data['review_cln'], test_size=0.33, random_state=42)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "next(iter(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9JG7IUOmcnb",
        "outputId": "ecd9c576-194f-483e-988e-208b9f0f916c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\"kaabee\" depicts the hardship of a woman in pre and during wwii raising her kids alone after her husband imprisoned for \"thought crime\" this movie was directed by yamada youji and as expected the atmosphere of this movie is really wonderful although the historical correctness of some scenes most notably the beach scene is a suspect  the acting in this movie is absolutely incredible i am baffled at how they managed to gather this allstar cast for a 2008 film yoshinaga sayuri possibly the most decorated stillactive actress in japan will undoubtedly win more individual awards for her performance in this film shoufukutei tsurube in a supporting role was really nice as well it was asano tadanobu though who delivered the most impressive performance perfectly portraying the wittiness of his character and the difficult situation he was in  films with prewar setting is not my thing but thanks to wonderful directing and acting i was totally absorbed by the story also it wasnt a farleft nonsense like \"yuunagi no machi sakura no kuni\" and examines the controversial and sensitive issue of government oppression and brainwashing that occurred in that period in japan excellent film highly recommended for all viewers'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir('data')\n",
        "except FileExistsError:\n",
        "  print('Directory already exisits')\n",
        "\n",
        "def save_tf_data(tf_data: tf.data.Dataset, dir_name: str) -> None:\n",
        "  \"\"\"\n",
        "  Saves the dataset\n",
        "  \"\"\"\n",
        "  path = os.path.join('data', dir_name)\n",
        "  tf.data.Dataset.save(tf_data, path)\n",
        "\n",
        "save_tf_data(train_dataset, 'train_data')\n",
        "save_tf_data(test_dataset, 'test_data')"
      ],
      "metadata": {
        "id": "OrHe4nhya5li"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tf_data(dir_name: str) -> tf.data.Dataset:\n",
        "    \"\"\"\n",
        "    Loads the tensorflow dataset\n",
        "    \"\"\"\n",
        "    path = os.path.join('data', dir_name)\n",
        "    return tf.data.Dataset.load(path)\n",
        "\n",
        "train_dataset = load_tf_data('train_data')\n",
        "test_dataset = load_tf_data('test_data')"
      ],
      "metadata": {
        "id": "hV20UXobdhZj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create tokeniser\n",
        "\n",
        "BERT requires tokens as input to the model. To create a custom tokeniser follow the steps below. Alternatively, a pre-trained model can be used instead."
      ],
      "metadata": {
        "id": "uyBXFvacaY3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.START_TOKEN = None\n",
        "        self.END_TOKEN = None\n",
        "        self.MASK_TOKEN = None\n",
        "        self.UNK_TOKEN = None\n",
        "    \n",
        "    def load_vocab(self, vocab):\n",
        "        self.START_TOKEN = vocab.index(\"[CLS]\")\n",
        "        self.END_TOKEN = vocab.index(\"[SEP]\")\n",
        "        self.MASK_TOKEN = vocab.index(\"[MASK]\")\n",
        "        self.UNK_TOKEN = vocab.index(\"[UNK]\")\n",
        "        \n",
        "    MAX_SEQ_LEN = 256\n",
        "    MAX_PREDICTIONS_PER_BATCH = 5\n",
        "    VOCAB_SIZE = 30000\n",
        "    BATCH_SIZE = 32\n",
        "    EMBED_DIM = 256  # Dimensionality of embeddings\n",
        "    NUM_HEAD = 4  # No. of attention heads\n",
        "    FF_DIM = 512  # Dimensionality of feed forward network\n",
        "    NUM_LAYERS = 4  # No. of layers\n",
        "    DROPOUT = 0.1\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "PfyrCkwbbGK_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer_params=dict(lower_case=True)\n",
        "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[MASK]\", \"[CLS]\", \"[SEP]\"]\n",
        "\n",
        "bert_vocab_args = dict(\n",
        "    # The target vocabulary size\n",
        "    vocab_size = config.VOCAB_SIZE,\n",
        "    # Reserved tokens that must be included in the vocabulary\n",
        "    reserved_tokens=reserved_tokens,\n",
        "    # Arguments for `text.BertTokenizer`\n",
        "    bert_tokenizer_params=bert_tokenizer_params,\n",
        "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
        "    learn_params={},\n",
        ")"
      ],
      "metadata": {
        "id": "DY6bfJtbiqQO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "imdb_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    train_dataset,\n",
        "    **bert_vocab_args\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBu6zbXRivyX",
        "outputId": "da2d469b-b36e-45d7-94a3-41787a44a798"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13min 8s, sys: 6 s, total: 13min 14s\n",
            "Wall time: 13min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('imdb_vocab.txt', 'w') as f:\n",
        "  for line in imdb_vocab:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "ZHV1n68Ut991"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('imdb_vocab.txt', 'r') as f:\n",
        "  imdb_vocab = f.read().splitlines() "
      ],
      "metadata": {
        "id": "As9oR8w8ukBG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add vocab to config dataset\n",
        "config.load_vocab(imdb_vocab)"
      ],
      "metadata": {
        "id": "3OvmfIvFzFjQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_table = tf.lookup.StaticVocabularyTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(\n",
        "      keys=imdb_vocab,\n",
        "      key_dtype=tf.string,\n",
        "      values=tf.range(\n",
        "          tf.size(imdb_vocab, out_type=tf.int64), dtype=tf.int64),\n",
        "          value_dtype=tf.int64\n",
        "        ),\n",
        "      num_oov_buckets=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "gxQPXRMuul__"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = text.BertTokenizer(\n",
        "      lookup_table,\n",
        "      token_out_type=tf.int64)"
      ],
      "metadata": {
        "id": "e45Le70cuWL6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize('Hello world')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxUMLguFjcp0",
        "outputId": "dc518bc2-7c13-4191-9f5f-97075864391d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[[1],\n",
              "  [258]]]>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mask inputs\n",
        "\n",
        "imdbBERT is trained on a masked language modelling task. This requires a portion of the input tokens to be masked. The model is then trained to predict the correct token to replace the mask."
      ],
      "metadata": {
        "id": "2FuPn-Vvbjwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def bert_pretrain_preprocess(vocab_table, feature):\n",
        "    # Input is a string Tensor of documents, shape [batch, 1].\n",
        "    # Tokenize segments to shape [num_sentences, (num_words)] each.\n",
        "    tokenizer = text.BertTokenizer(\n",
        "        vocab_table,\n",
        "        token_out_type=tf.int64)\n",
        "\n",
        "    segments = tokenizer.tokenize(feature).merge_dims(1, -1)\n",
        "\n",
        "    # Truncate inputs to a maximum length.\n",
        "    trimmer = text.RoundRobinTrimmer(max_seq_length=config.MAX_SEQ_LEN)\n",
        "    trimmed_segments = trimmer.trim([segments])\n",
        "\n",
        "    # Combine segments, get segment ids and add special tokens.\n",
        "    segments_combined, segment_ids = text.combine_segments(\n",
        "        trimmed_segments,\n",
        "        start_of_sequence_id=config.START_TOKEN,\n",
        "        end_of_segment_id=config.END_TOKEN)\n",
        "\n",
        "    random_selector = text.RandomItemSelector(\n",
        "        max_selections_per_batch=config.MAX_PREDICTIONS_PER_BATCH,\n",
        "        selection_rate=0.2,\n",
        "        unselectable_ids=[config.START_TOKEN, config.END_TOKEN, config.UNK_TOKEN]\n",
        "    )\n",
        "\n",
        "    mask_values_chooser = text.MaskValuesChooser(config.VOCAB_SIZE, config.MASK_TOKEN, 0.8)\n",
        "\n",
        "    # Apply dynamic masking task.\n",
        "    masked_input_ids, masked_lm_positions, masked_lm_ids = (\n",
        "        text.mask_language_model(\n",
        "            segments_combined,\n",
        "            random_selector,\n",
        "            mask_values_chooser,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    padded_inputs, _ = text.pad_model_inputs(\n",
        "        segments_combined, max_seq_length=config.MAX_SEQ_LEN)\n",
        "\n",
        "    # Prepare and pad combined segment inputs\n",
        "    masked_word_ids, input_mask = text.pad_model_inputs(\n",
        "        masked_input_ids, max_seq_length=config.MAX_SEQ_LEN)\n",
        "\n",
        "    return masked_word_ids, padded_inputs"
      ],
      "metadata": {
        "id": "5e8sPYFFgn1i"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(ds: tf.data.Dataset, lk_up, BUFFER_SIZE: int = 20000, BATCH_SIZE: int = 64):\n",
        "    \"\"\"\n",
        "    It tokenizes the text, and filters out the sequences that are too long. (The batch/unbatch is included because the\n",
        "    tokenizer is much more efficient on large batches). The cache method ensures that that work is only executed once.\n",
        "    Then shuffle and, dense_to_ragged_batch randomize the order and assemble batches of examples. Finally, prefetch runs\n",
        "    the dataset in parallel with the model to ensure that data is available when needed. See Better performance with the\n",
        "    tf.data for details.\n",
        "    :param ds: Tensorflow dataset\n",
        "    :param BUFFER_SIZE: Size of buffer (randomly samples elements from buffer)\n",
        "    :param BATCH_SIZE: No. of elements within a batch\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    return (\n",
        "        ds\n",
        "        .shuffle(BUFFER_SIZE)\n",
        "        .batch(BATCH_SIZE)\n",
        "        .map(functools.partial(bert_pretrain_preprocess, lookup_table))\n",
        "        .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
        "\n",
        "\n",
        "train_dataset_masked = make_batches(train_dataset, lookup_table)\n",
        "test_dataset_masked = make_batches(test_dataset, lookup_table)"
      ],
      "metadata": {
        "id": "9S5_6TobhZIW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "h3E-C8Onc_sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    PositionEmbedding layer that looks-up a token's embedding vector and adds the position vector\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = self.positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "    @staticmethod\n",
        "    def positional_encoding(length: int, depth: int):\n",
        "        \"\"\"\n",
        "        A Transformer adds a \"Positional Encoding\" to the embedding vectors. It uses a set of sines and cosines at\n",
        "        different frequencies (across the sequence).\n",
        "\n",
        "        :param length: Length of position embedding vector\n",
        "        :param depth: Size of feed forward neural network\n",
        "        :return: Positional encoding vector\n",
        "        \"\"\"\n",
        "        depth = depth / 2\n",
        "\n",
        "        positions = np.arange(length)[:, np.newaxis]  # (seq, 1)\n",
        "        depths = np.arange(depth)[np.newaxis, :] / depth  # (1, depth)\n",
        "\n",
        "        angle_rates = 1 / (10000 ** depths)  # (1, depth)\n",
        "        angle_rads = positions * angle_rates  # (pos, depth)\n",
        "\n",
        "        pos_encoding = np.concatenate(\n",
        "            [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "            axis=-1)\n",
        "\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        # This factor sets the relative scale of the embedding and positional_encoding.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention layers are used throughout the model. These are all identical except for how the attention is configured.\n",
        "    Each one contains a layers.MultiHeadAttention, a layers.LayerNormalization and a layers.Add.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.last_attn_scores = None\n",
        "\n",
        "\n",
        "\n",
        "class GlobalSelfAttention(BaseAttention):\n",
        "    \"\"\"\n",
        "    This layer is responsible for processing the context sequence, and propagating information along its length.\n",
        "    Since the context sequence is fixed while the translation is being generated, information is allowed to flow in\n",
        "    both directions.\n",
        "\n",
        "    To implement this layer you just need to pass the target sequence, x, as both the query, and value\n",
        "    arguments to the mha layer:\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "\n",
        "        :param x: Target sequence\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        attn_output = self.mha(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    The transformer also includes this point-wise feed-forward network in both the encoder and decoder.\n",
        "    The network consists of two linear layers (tf.keras.layers.Dense) with a ReLU activation in-between, and a\n",
        "    dropout layer.\n",
        "    As with the attention layers, the code here also includes the residual connection and normalization.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.seq = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layer_norm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    The encoder contains a stack of N encoder layers. Where each EncoderLayer contains a GlobalSelfAttention\n",
        "    and FeedForward layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attention = GlobalSelfAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=d_model,\n",
        "            dropout=dropout_rate)\n",
        "\n",
        "        self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.self_attention(x)\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    The encoder consists of:\n",
        "        - A PositionalEmbedding layer at the input.\n",
        "        - A stack of EncoderLayer layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *, num_layers, d_model, num_heads,\n",
        "                 dff, vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(\n",
        "            vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model=d_model,\n",
        "                         num_heads=num_heads,\n",
        "                         dff=dff,\n",
        "                         dropout_rate=dropout_rate)\n",
        "            for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        # `x` is token-IDs shape: (batch, seq_len)\n",
        "        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "        # Add dropout.\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x)\n",
        "\n",
        "        return x  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "\n",
        "class imdbBERT(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Put Encoder and Decoder together and add a final linear (Dense) layer which converts the resulting vector at\n",
        "    each location into output token probabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "                 input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                               num_heads=num_heads, dff=dff,\n",
        "                               vocab_size=input_vocab_size,\n",
        "                               dropout_rate=dropout_rate)\n",
        "\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "        # first argument.\n",
        "        encoded = self.encoder(inputs)  # (batch_size, context_len, d_model)        \n",
        "\n",
        "        # Final linear layer output.\n",
        "        logits = self.final_layer(encoded)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "        try:\n",
        "            # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        # Return the final output and the attention weights.\n",
        "        return logits"
      ],
      "metadata": {
        "id": "MqeO1Oj7iu8C"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training functions\n",
        "\n",
        "A custom schedule is used to vary the learning rate during training. Masked loss/accuracy as used to determine model progress"
      ],
      "metadata": {
        "id": "zDZkBkT0dMjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {\n",
        "        'd_model': self.d_model,\n",
        "        'warmup_steps': self.warmup_steps,\n",
        "\n",
        "        }\n",
        "        return config\n",
        "\n",
        "\n",
        "def masked_loss(label, pred):\n",
        "    mask = label != 0\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_object(label, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "    pred = tf.argmax(pred, axis=2)\n",
        "    label = tf.cast(label, pred.dtype)\n",
        "    match = label == pred\n",
        "\n",
        "    mask = label != 0\n",
        "\n",
        "    match = match & mask\n",
        "\n",
        "    match = tf.cast(match, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(match) / tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "W34nSKMYkPcm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This callback outputs how the model is progressing against a static task. It is predicting output tokens for the phrase:\n",
        "\n",
        "*I have watched this **[MASK]** and it was awesome* "
      ],
      "metadata": {
        "id": "HW_DI7z8deB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedTextGenerator(Callback):\n",
        "    def __init__(self, sample_tokens, vocab, top_k=5):\n",
        "        self.id2token = dict(enumerate(vocab))\n",
        "        self.token2id = {y: x for x, y in self.id2token.items()}\n",
        "        self.sample_tokens = sample_tokens\n",
        "        self.k = top_k\n",
        "        self.mask_token_id = self.token2id.get('[MASK]')\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        return \" \".join([self.id2token[t] for t in tokens if t != 0])\n",
        "\n",
        "    def convert_ids_to_tokens(self, id):\n",
        "        return self.id2token[id]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        prediction = self.model.predict(self.sample_tokens)\n",
        "\n",
        "        masked_index = np.where(self.sample_tokens == self.mask_token_id)\n",
        "        masked_index = masked_index[1]\n",
        "        mask_prediction = prediction[0][masked_index]\n",
        "\n",
        "        top_indices = mask_prediction[0].argsort()[-self.k:][::-1]\n",
        "        values = mask_prediction[0][top_indices]\n",
        "\n",
        "        for i in range(len(top_indices)):\n",
        "            p = top_indices[i]\n",
        "            v = values[i]\n",
        "            tokens = np.copy(self.sample_tokens[0])\n",
        "            tokens[masked_index[0]] = p\n",
        "            result = {\n",
        "                \"input_text\": self.decode(self.sample_tokens[0].numpy()),\n",
        "                \"prediction\": self.decode(tokens),\n",
        "                \"probability\": v,\n",
        "                \"predicted mask token\": self.convert_ids_to_tokens(p),\n",
        "            }\n",
        "            print(result)\n"
      ],
      "metadata": {
        "id": "wAdBwut89W1B"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile Model"
      ],
      "metadata": {
        "id": "33grr_QxdxOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = imdbBERT(\n",
        "    num_layers=config.NUM_LAYERS,\n",
        "    d_model=config.EMBED_DIM,\n",
        "    num_heads=config.NUM_HEAD,\n",
        "    dff=config.FF_DIM,\n",
        "    input_vocab_size=config.VOCAB_SIZE,\n",
        "    target_vocab_size=config.VOCAB_SIZE,\n",
        "    dropout_rate=config.DROPOUT)\n",
        "\n",
        "learning_rate = CustomSchedule(config.EMBED_DIM)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "HR0OUttFmdNo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Text to test with: \"i have watched this [MASK] and it was awesome\"\n",
        "sample_tokens = tf.ragged.constant([[28, 100, 365, 86, 2, 80, 85, 88, 1223]])\n",
        "\n",
        "masked_token_ids, _ = text.pad_model_inputs(\n",
        "    sample_tokens, max_seq_length=config.MAX_SEQ_LEN)\n",
        "\n",
        "generator_callback = MaskedTextGenerator(masked_token_ids, imdb_vocab) "
      ],
      "metadata": {
        "id": "gWZxF7dVF5LT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.detokenize([[28, 100, 365, 86, 2, 80, 85, 88, 1223]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkbTVnbBnesW",
        "outputId": "38d5bc9e-99b3-4784-ffaa-06f16d7ebab8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'i', b'have', b'watched', b'this', b'[MASK]', b'and', b'it', b'was',\n",
              "  b'awesome']]>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.gather(imdb_vocab, masked_token_ids)"
      ],
      "metadata": {
        "id": "9LvAC9ZZQ-nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "-K-WtU3xeBhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(train_dataset_masked,\n",
        "                epochs=3,\n",
        "                validation_data=test_dataset_masked,\n",
        "                callbacks=[generator_callback])"
      ],
      "metadata": {
        "id": "kaAxLDD3o3EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq0H2uZMQYPH",
        "outputId": "543d0b3c-3671-4847-c94a-5bd010395a0f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"imdb_bert\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  12943360  \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  7710000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,653,360\n",
            "Trainable params: 20,653,360\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save/Load Model\n",
        "\n",
        "The custom learning rate schedule means we need to save the model weights instead of the whole model. The checkpoints can then be reloaded into a new model later on for inference"
      ],
      "metadata": {
        "id": "G11AOMbReF6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save_weights('/checkpoints/my_checkpoint')"
      ],
      "metadata": {
        "id": "5CPMUehR7dOc"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = imdbBERT(\n",
        "    num_layers=config.NUM_LAYERS,\n",
        "    d_model=config.EMBED_DIM,\n",
        "    num_heads=config.NUM_HEAD,\n",
        "    dff=config.FF_DIM,\n",
        "    input_vocab_size=config.VOCAB_SIZE,\n",
        "    target_vocab_size=config.VOCAB_SIZE,\n",
        "    dropout_rate=config.DROPOUT)"
      ],
      "metadata": {
        "id": "POP9Sa5Y1070"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.load_weights('/checkpoints/my_checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcGMTHRF4v9e",
        "outputId": "3fa0e583-4040-4d87-a123-84d8415d24a7"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fbf60814150>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = loaded_model.predict(masked_token_ids)\n",
        "masked_index = np.where(masked_token_ids == 2)\n",
        "masked_index = masked_index[1]\n",
        "mask_prediction = prediction[0][masked_index]\n",
        "top_indices = mask_prediction[0].argsort()[-5 :][::-1]\n",
        "values = mask_prediction[0][top_indices]\n",
        "values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSTatl_sE6F7",
        "outputId": "eacccb71-abc7-48b6-e1b6-2af21cd1c1ca"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.53967685, 0.48042318, 0.47334057, 0.47148484, 0.4674449 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    }
  ]
}